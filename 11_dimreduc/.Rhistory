demo()
demo(plotmath)
contour(volcano)
elevation<-matrix(1,100,100)
elevation[4,6:10]<-0
contour(elevation)
persp(elevation)
persp(elevation, expand=0.2)
contour(volcano)
volcano
persp(volcano)
persp(volcano, expand=0.2)
image(volcano)
help(image)
image(volcano, rainbow)
image(volcano)
help(seq)
pwm<-c(seq.int(25,250,25))
plot(voltage, current2)
current2 <- c(0.33, 0.66, 0.98, 1.30, 1.62, 1.94, 2.26, 2.59, 2.91)
plot(voltage, current2)
source('~/Desktop/Electronics:Computers/R/test arduino pwm vs voltage.R')
source('~/Desktop/Electronics:Computers/R/test arduino pwm vs voltage.R')
source('~/Desktop/Electronics:Computers/R/test arduino pwm vs voltage.R')
install.packages("swirl")
library("swirl")
swirl
swirl()
5+&
5+7
bye()
swirl()
getwd()
ls()
x <- 9
ls()
list.files()
?list.files
args(list.files)
old.dir <- getwd()
cd rstats
dir.create(rstats)
dir.create?
dir.create(tesdir)
dir.create('testdir')
setwd('testdir')
file.create(mytest.R)
file.create('mytest.R')
ls
list.files
list.files()
file.exists?
help(file.exists)
file.exists("mytest.R")
help(file.info)
file.info("mytest.R")
file.rename?
?file.rename
file.rename("mytest.R","mytest2.R")
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
?file.path
file.path("folder1", "folder2")
?dir.create
?
dir.create("testdir2")
dir.create(file.path('tesdir2', 'testdir3'), recursive = TRUE)
info()
dir.create(file.path('testdir2', 'testdir3'), recursive = TRUE)
file.path(getwd())
play()
file.path((getwd()))
setwd('..')
getwd()
?unlink()
nxt()
setwd(/Users/Robert)
setwd('/Users/Robert')
setwd(old.dir)
unlink('testdir', recursive = TRUE)
swirl()
swirl()
load.packages
library("swirl")
ls
ls()
rm(list = ls())
ls
ls()
swirl()
1:20
pi:10
15:1
?
?':'
?seq
seq(1,20)
seq(0,10, by=0.5)
seq(5,10, length = 30)
my_seq <- seq(5,19, length=30)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
?rep
rep(0, times = 40)
rep(c(0,1,2), times = 10)
rep(c(0,1,2), each = 10)
num_vect <- c(0.5,55,-10,6)
tf <- (num_vect < 1)
tf <- num_vect < 1
print(tf)
tf
num_vect >= 6
my_char <- c("my", "name", "is")
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
play()
?paste
nxt()
my_name <- c(my_char, "Robert")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(1:3, c("X","Y","Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
swirl()
swirlstats()
library("swirl")
swirl()
c(0.5,55-10,6)
quit
quit()
bye()
swirl()
setwd("~/Desktop/Comsci/machine_learning/Udemy_ML/11_dimreduc")
ds = read.csv('Wine.csv')
View(ds)
library(caTools)
ds[,1:2] = scale(ds[,1:2])
library(caTools)
ds[,1:2] = scale(ds[,1:2])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.75)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
ds = read.csv('Wine.csv')
ds = ds[, 3:5]
# Scaling and splitting
library(caTools)
ds[,1:2] = scale(ds[,1:2])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Classifier
ds = read.csv('Wine.csv')
ds = ds[, 3:5]
# Scaling and splitting
library(caTools)
ds[,1:2] = scale(ds[,1:2])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Classifier
ds = read.csv('Wine.csv')
ds = ds[, 3:5]
# Scaling and splitting
library(caTools)
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
split = sample.split(ds$Customer_Segment, SplitRatio = 0.75)
ds = read.csv('Wine.csv')
ds = read.csv('Wine.csv')
# Scaling and splitting
library(caTools)
split = sample.split(ds$Customer_Segment, SplitRatio = 0.75)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
ds = read.csv('Wine.csv')
# Scaling and splitting
library(caTools)
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Classifier
install.packages('Caret')
install.packages('caret')
library(caret)
install.packages('SparseM')
library(caret)
install.packages('SparseM')
library(caret)
library(e1071)
pca = preProcess(train[-14], method = 'pca', pcaComp=2)
train_new = predict(pca, train)
View(train_new)
train_new = train_new[c(2,3,1)]
View(train_new)
ds = read.csv('Wine.csv')
pca = preProcess(ds[-14], method = c('scale', 'pca'), pcaComp=2)
ds = predict(pca, ds)
View(ds)
ds = ds[(2,3,1)]
ds = ds[c(2,3,1)]
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
View(test)
clf = svm(Purchased ~ .,
data = train,
kernel = 'radial',
type = 'C-classification')
y_pred = predict(clf, type = 'response', newdata = test[-3])
cm
# Confusion matrix
cm = table(test[, 3], y_pred)
plot(clf, data = train)
clf = svm(Purchased ~ .,
data = train,
kernel = 'radial',
type = 'C-classification')
clf = svm(Customer_Segment ~ .,
data = train,
kernel = 'radial',
type = 'C-classification')
y_pred = predict(clf, type = 'response', newdata = test[-3])
cm
cm = table(test[, 3], y_pred)
cm
plot(clf, data = train)
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3'), 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'deepskyblue', ifelse(set[, 3] == 1, 'green4', 'red3')))
prob_set
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(clf, type = 'response', newdata = grid_set)
prob_set
colnames(grid_set) = c('PC1', 'PC2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
y_grid = prob_set
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3'), 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'deepskyblue', ifelse(set[, 3] == 1, 'green4', 'red3')))
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3'), 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
install.packages(ElemStatLearn)
install.packages('ElemStatLearn')
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3'), 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
source('~/Desktop/Comsci/machine_learning/Udemy_ML/11_dimreduc/PCA.R', echo=TRUE)
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'SVM with PCA',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
ds = read.csv('Wine.csv')
# Split the dataset
library(caTools)
ds[-14] = scale(ds[-14])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
library(MASS)
library(MASS)
lda = lda(Customer_Segment ~., data = train)
train = predict(lda, train)
ds = read.csv('Wine.csv')
# Scale and split the dataset
library(caTools)
ds[-14] = scale(ds[-14])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Applying LDA
library(MASS)
lda = lda(Customer_Segment ~., data = train)
train = as.data.frame(predict(lda, train))
ds = read.csv('Wine.csv')
library(caTools)
ds[-14] = scale(ds[-14])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Applying LDA
library(MASS)
lda = lda(Customer_Segment ~., data = train)
train = as.data.frame(predict(lda, train))
View(train)
train = train[c(5,6,1)]
View(train)
# SVM classifier
library(e1071)
clf = svm(class ~ .,
data = train,
kernel = 'radial',
type = 'C-classification')
y_pred = predict(clf, type = 'response', newdata = test[-3])
library(e1071)
clf = svm(class ~ .,
data = train,
kernel = 'radial',
type = 'C-classification')
y_pred = predict(clf, type = 'response', newdata = test[-3])
y_pred = predict(clf, newdata = test[-3])
y_pred = predict(clf, newdata = test[-3])
library(e1071)
clf = svm(class ~ .,
data = train,
kernel = 'linear',
type = 'C-classification')
y_pred = predict(clf, newdata = test[-3])
test = as.data.frame(predict(lda, test))[c(5,6,1)]
test = as.data.frame(predict(lda, test))
test = test[c(5,6,1)]
ds = read.csv('Wine.csv')
# Scale and split the dataset
library(caTools)
ds[-14] = scale(ds[-14])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Applying LDA
library(MASS)
lda = lda(Customer_Segment ~., data = train)
train = as.data.frame(predict(lda, train))
train = train[c(5,6,1)]
test = as.data.frame(predict(lda, test))
test = test[c(5,6,1)]
# SVM classifier
library(e1071)
clf = svm(class ~ .,
data = train,
kernel = 'linear',
type = 'C-classification')
y_pred = predict(clf, newdata = test[-3])
# Confusion matrix
cm = table(test[, 3], y_pred)
plot(clf, data = train)
cm
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'SVM with PCA',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'SVM with LDA',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
ds = read.csv('Wine.csv')
# Scale and split the dataset
library(caTools)
ds[-14] = scale(ds[-14])
split = sample.split(ds$Customer_Segment, SplitRatio = 0.8)
train = subset(ds, split == TRUE)
test = subset(ds, split == FALSE)
# Applying LDA
library(MASS)
lda = lda(Customer_Segment ~., data = train)
train = as.data.frame(predict(lda, train))
train = train[c(5,6,1)]
test = as.data.frame(predict(lda, test))
test = test[c(5,6,1)]
# SVM classifier
library(e1071)
clf = svm(class ~ .,
data = train,
kernel = 'radial',
type = 'C-classification')
y_pred = predict(clf, newdata = test[-3])
# Confusion matrix
cm = table(test[, 3], y_pred)
plot(clf, data = train)
# Plotting
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'SVM with LDA',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
library('ElemStatLearn')
set = train
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
prob_set = predict(clf, type = 'response', newdata = grid_set)
y_grid = prob_set
plot(set[, -3],
main = 'SVM with LDA',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
